{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import transformers\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import AutoTokenizer, BertModel, DistilBertModel\n",
    "from transformers import AutoModel\n",
    "\n",
    "from datasets import Dataset, ClassLabel\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from torch.nn import TripletMarginLoss\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### PARAMS\n",
    "MAX_SAMPLES = 10000\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-3\n",
    "EPOCHS = 20\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        short_description   category\n0       Health experts said it is too early to predict...  U.S. NEWS\n1       He was subdued by passengers and crew when he ...  U.S. NEWS\n2       \"Until you have a dog you don't understand wha...     COMEDY\n3       \"Accidentally put grown-up toothpaste on my to...  PARENTING\n4       Amy Cooper accused investment firm Franklin Te...  U.S. NEWS\n...                                                   ...        ...\n209522  Verizon Wireless and AT&T are already promotin...       TECH\n209523  Afterward, Azarenka, more effusive with the pr...     SPORTS\n209524  Leading up to Super Bowl XLVI, the most talked...     SPORTS\n209525  CORRECTION: An earlier version of this story i...     SPORTS\n209526  The five-time all-star center tore into his te...     SPORTS\n\n[189815 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>short_description</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Health experts said it is too early to predict...</td>\n      <td>U.S. NEWS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>He was subdued by passengers and crew when he ...</td>\n      <td>U.S. NEWS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Until you have a dog you don't understand wha...</td>\n      <td>COMEDY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n      <td>PARENTING</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Amy Cooper accused investment firm Franklin Te...</td>\n      <td>U.S. NEWS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>209522</th>\n      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n      <td>TECH</td>\n    </tr>\n    <tr>\n      <th>209523</th>\n      <td>Afterward, Azarenka, more effusive with the pr...</td>\n      <td>SPORTS</td>\n    </tr>\n    <tr>\n      <th>209524</th>\n      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n      <td>SPORTS</td>\n    </tr>\n    <tr>\n      <th>209525</th>\n      <td>CORRECTION: An earlier version of this story i...</td>\n      <td>SPORTS</td>\n    </tr>\n    <tr>\n      <th>209526</th>\n      <td>The five-time all-star center tore into his te...</td>\n      <td>SPORTS</td>\n    </tr>\n  </tbody>\n</table>\n<p>189815 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_csv('dataset/tweet_dataset.csv')\n",
    "dataset_df.dropna(inplace=True)\n",
    "dataset_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X, y = dataset_df[['short_description']], dataset_df[['category']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Undersampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = undersampler.fit_resample(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### One-hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konsz\\OneDrive\\Pulpit\\Inne\\AKAI-Hack\\akai-code\\data-science\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "oh_encoder = LabelEncoder()\n",
    "y_enc = oh_encoder.fit_transform(y_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'labels'],\n    num_rows: 36246\n})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = {\"text\": X_res[\"short_description\"], \"labels\": y_enc.tolist()}\n",
    "data_df = Dataset.from_dict(data_df)\n",
    "data_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/36246 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a361562152c94fc08fc8a2e4238a1ec9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "dataset_features = data_df.features.copy()\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dataset = data_df.map(tokenize_function)\n",
    "dataset.features['labels'] = ClassLabel(num_classes=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 36246\n})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"text\"])\n",
    "dataset.set_format(\"torch\")\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.1, stratify_by_column=\"labels\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class TweetDataset(TorchDataset):\n",
    "    def __init__(self, dataset: Dataset):\n",
    "        self.input_ids = dataset['input_ids']\n",
    "        self.labels = dataset['labels']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        anchor = self.input_ids[item]\n",
    "        anchor_class = self.labels[item]\n",
    "\n",
    "        positive_indices = self.labels == anchor_class\n",
    "        positive_indices = positive_indices.nonzero()\n",
    "        positive_idx = positive_indices[torch.randint(high=len(positive_indices), size=(1, ))[0]]\n",
    "        positive_example = self.input_ids[positive_idx].flatten()\n",
    "\n",
    "        negative_indices = self.labels != anchor_class\n",
    "        negative_indices = negative_indices.nonzero()\n",
    "        negative_idx = negative_indices[torch.randint(high=len(negative_indices), size=(1, ))[0]]\n",
    "        negative_example = self.input_ids[negative_idx].flatten()\n",
    "\n",
    "        return anchor, positive_example, negative_example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_ds = TweetDataset(split_dataset['train'])\n",
    "test_ds = TweetDataset(split_dataset['test'])\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class TweetBERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-cased\")\n",
    "        self.pooler = torch.nn.Linear(768, 768)\n",
    "        self.tahn = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(x)\n",
    "        x = self.pooler(x[0][:, 0])\n",
    "        return self.tahn(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = TweetBERT()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model = model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "loss = TripletMarginLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/konradszewczyk/TweetBuble/e/BUBL-2\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:06<2:28:44,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 train: 0.85127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<03:20,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 val: 1.00152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:04<1:36:57,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 train: 0.90016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<03:21,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 val: 1.00014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:04<1:36:54,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 train: 1.03017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<03:20,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 val: 0.99296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:04<1:37:02,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 train: 1.01906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<03:22,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 val: 0.99995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:04<1:38:06,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 train: 0.93915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:21,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 val: 1.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:02:07,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 train: 1.05140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:22,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:03:10,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 train: 0.82400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:24,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 val: 1.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:03:05,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 train: 1.25484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:23,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:04:13,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 train: 1.11090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:25,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:03:41,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 train: 0.80786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:26,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 val: 0.99999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:04:51,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: 0.93233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:30,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:04:42,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 train: 0.85853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:33,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:06:27,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 train: 0.78794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:32,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:07:12,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 train: 0.88644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:34,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:09:01,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 train: 1.12574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:36,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:10:29,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 train: 1.04508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:39,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:09:07,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 train: 0.91829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:40,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:10:23,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 train: 1.05268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:39,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:11:09,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 train: 0.88627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:42,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 val: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8156 [00:05<2:11:28,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 train: 0.78470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/907 [00:01<04:41,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 val: 1.00000\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 26 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 26 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/konradszewczyk/TweetBuble/e/BUBL-2\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"konradszewczyk/TweetBuble\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI0MWIyOTA1ZS03ODc3LTQ5MzQtYjk0OS05ZjNjYzdiMDFjMDcifQ==\",\n",
    ")\n",
    "\n",
    "os.mkdir(os.path.join('models', run['sys/id'].fetch()))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss_log = []\n",
    "    for batch_idx, (anchor, positive_ex, negative_ex) in enumerate(tqdm(train_dl)):\n",
    "        anchor = anchor.to(device=device)\n",
    "        archor_output = model(anchor)\n",
    "\n",
    "        positive_ex = positive_ex.to(device=device)\n",
    "        positive_ex_output = model(positive_ex)\n",
    "\n",
    "        negative_ex = negative_ex.to(device=device)\n",
    "        negative_ex_output = model(negative_ex)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss(archor_output, positive_ex_output, negative_ex_output)\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_log.append(train_loss.detach().cpu())\n",
    "\n",
    "    train_loss = np.mean(train_loss_log)\n",
    "    run['train_loss'].log(train_loss)\n",
    "    print(\"Epoch {:02d} train: {:.5f}\".format(epoch, train_loss))\n",
    "\n",
    "    file_name = 'epoch-{:02d}.pt'.format(epoch)\n",
    "    PATH = os.path.join('models', run['sys/id'].fetch(), file_name)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss_log = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (anchor, positive_ex, negative_ex) in enumerate(tqdm(test_dl)):\n",
    "            anchor = anchor.to(device=device)\n",
    "            archor_output = model(anchor)\n",
    "\n",
    "            positive_ex = positive_ex.to(device=device)\n",
    "            positive_ex_output = model(positive_ex)\n",
    "\n",
    "            negative_ex = negative_ex.to(device=device)\n",
    "            negative_ex_output = model(negative_ex)\n",
    "\n",
    "            test_loss = loss(archor_output, positive_ex_output, negative_ex_output)\n",
    "\n",
    "            test_loss_log.append(test_loss.cpu())\n",
    "\n",
    "    test_loss = np.mean(test_loss_log)\n",
    "    run['test_loss'].log(test_loss)\n",
    "    print(\"Epoch {:02d} val: {:.5f}\".format(epoch, test_loss))\n",
    "\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([768])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_ex_output[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "TweetBERT(\n  (bert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pooler): Linear(in_features=768, out_features=768, bias=True)\n  (tahn): Tanh()\n)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "InactiveRunException",
     "evalue": "\n\n----InactiveRunException----------------------------------------\n\nIt seems you are trying to log metadata to (or fetch it from) a run that was stopped (BUBL-2).\n\nHere's what you can do:\n    - Resume the run to continue logging to it:\n    https://docs.neptune.ai/logging/to_existing_object/\n    - Don't invoke `stop()` on a run that you want to access. If you want to stop monitoring only,\n    you can resume a run in read-only mode:\n    https://docs.neptune.ai/api/connection_modes/#read-only-mode\n\nYou may also want to check the following docs pages:\n    - https://docs.neptune.ai/logging/to_existing_object/\n    - https://docs.neptune.ai/usage/querying_metadata/\n\nNeed help?-> https://docs.neptune.ai/getting_help\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInactiveRunException\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [27], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mrun\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msys/id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mfetch()\n",
      "File \u001B[1;32m~\\OneDrive\\Pulpit\\Inne\\AKAI-Hack\\akai-code\\data-science\\venv\\lib\\site-packages\\neptune\\new\\metadata_containers\\metadata_container.py:101\u001B[0m, in \u001B[0;36mensure_not_stopped.<locals>.inner_fun\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m ContainerState\u001B[38;5;241m.\u001B[39mSTOPPED:\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontainer_type \u001B[38;5;241m==\u001B[39m ContainerType\u001B[38;5;241m.\u001B[39mRUN:\n\u001B[1;32m--> 101\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InactiveRunException(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_label)\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontainer_type \u001B[38;5;241m==\u001B[39m ContainerType\u001B[38;5;241m.\u001B[39mPROJECT:\n\u001B[0;32m    103\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InactiveProjectException(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_label)\n",
      "\u001B[1;31mInactiveRunException\u001B[0m: \n\n----InactiveRunException----------------------------------------\n\nIt seems you are trying to log metadata to (or fetch it from) a run that was stopped (BUBL-2).\n\nHere's what you can do:\n    - Resume the run to continue logging to it:\n    https://docs.neptune.ai/logging/to_existing_object/\n    - Don't invoke `stop()` on a run that you want to access. If you want to stop monitoring only,\n    you can resume a run in read-only mode:\n    https://docs.neptune.ai/api/connection_modes/#read-only-mode\n\nYou may also want to check the following docs pages:\n    - https://docs.neptune.ai/logging/to_existing_object/\n    - https://docs.neptune.ai/usage/querying_metadata/\n\nNeed help?-> https://docs.neptune.ai/getting_help\n"
     ]
    }
   ],
   "source": [
    "run['sys/id'].fetch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d23b1cc31408ba59c72afb03ce07d8c08db8e1ae7bdb80d27747a1bfbd8e34d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}