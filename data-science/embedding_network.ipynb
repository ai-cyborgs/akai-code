{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import transformers\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import AutoTokenizer, BertModel, DistilBertModel\n",
    "from transformers import AutoModel\n",
    "\n",
    "from datasets import Dataset, ClassLabel\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from torch.nn import TripletMarginLoss\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### PARAMS\n",
    "MAX_SAMPLES = 10000\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-3\n",
    "EPOCHS = 20\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        short_description   category\n0       Health experts said it is too early to predict...  U.S. NEWS\n1       He was subdued by passengers and crew when he ...  U.S. NEWS\n2       \"Until you have a dog you don't understand wha...     COMEDY\n3       \"Accidentally put grown-up toothpaste on my to...  PARENTING\n4       Amy Cooper accused investment firm Franklin Te...  U.S. NEWS\n...                                                   ...        ...\n209522  Verizon Wireless and AT&T are already promotin...       TECH\n209523  Afterward, Azarenka, more effusive with the pr...     SPORTS\n209524  Leading up to Super Bowl XLVI, the most talked...     SPORTS\n209525  CORRECTION: An earlier version of this story i...     SPORTS\n209526  The five-time all-star center tore into his te...     SPORTS\n\n[189815 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>short_description</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Health experts said it is too early to predict...</td>\n      <td>U.S. NEWS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>He was subdued by passengers and crew when he ...</td>\n      <td>U.S. NEWS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Until you have a dog you don't understand wha...</td>\n      <td>COMEDY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n      <td>PARENTING</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Amy Cooper accused investment firm Franklin Te...</td>\n      <td>U.S. NEWS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>209522</th>\n      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n      <td>TECH</td>\n    </tr>\n    <tr>\n      <th>209523</th>\n      <td>Afterward, Azarenka, more effusive with the pr...</td>\n      <td>SPORTS</td>\n    </tr>\n    <tr>\n      <th>209524</th>\n      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n      <td>SPORTS</td>\n    </tr>\n    <tr>\n      <th>209525</th>\n      <td>CORRECTION: An earlier version of this story i...</td>\n      <td>SPORTS</td>\n    </tr>\n    <tr>\n      <th>209526</th>\n      <td>The five-time all-star center tore into his te...</td>\n      <td>SPORTS</td>\n    </tr>\n  </tbody>\n</table>\n<p>189815 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_csv('dataset/tweet_dataset.csv')\n",
    "dataset_df.dropna(inplace=True)\n",
    "dataset_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X, y = dataset_df[['short_description']], dataset_df[['category']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Undersampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = undersampler.fit_resample(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### One-hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konsz\\OneDrive\\Pulpit\\Inne\\AKAI-Hack\\akai-code\\data-science\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "oh_encoder = LabelEncoder()\n",
    "y_enc = oh_encoder.fit_transform(y_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'labels'],\n    num_rows: 36246\n})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = {\"text\": X_res[\"short_description\"], \"labels\": y_enc.tolist()}\n",
    "data_df = Dataset.from_dict(data_df)\n",
    "data_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/36246 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a7b4d732d914dd5868a9bbc93528df6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "dataset_features = data_df.features.copy()\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dataset = data_df.map(tokenize_function)\n",
    "dataset.features['labels'] = ClassLabel(num_classes=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 36246\n})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"text\"])\n",
    "dataset.set_format(\"torch\")\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle().select(range(5000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.1, stratify_by_column=\"labels\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class TweetDataset(TorchDataset):\n",
    "    def __init__(self, dataset: Dataset):\n",
    "        self.input_ids = dataset['input_ids']\n",
    "        self.attention_mask = dataset['attention_mask']\n",
    "        self.dataset = dataset.remove_columns(\"labels\")\n",
    "        self.labels = dataset['labels']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        #anchor = self.input_ids[item]\n",
    "        anchor = self.dataset[item]\n",
    "        anchor_class = self.labels[item]\n",
    "        #anchor_attention = self.attention_mask[item]\n",
    "\n",
    "\n",
    "        positive_indices = self.labels == anchor_class\n",
    "        positive_indices = positive_indices.nonzero()\n",
    "        positive_idx = positive_indices[torch.randint(high=len(positive_indices), size=(1, ))[0]]\n",
    "        #positive_example = self.input_ids[positive_idx].flatten()\n",
    "        #positive_attention = self.attention_mask[positive_idx]\n",
    "        positive_example = self.dataset[positive_idx]\n",
    "\n",
    "        negative_indices = self.labels != anchor_class\n",
    "        negative_indices = negative_indices.nonzero()\n",
    "        negative_idx = negative_indices[torch.randint(high=len(negative_indices), size=(1, ))[0]]\n",
    "        #negative_example = self.input_ids[negative_idx].flatten()\n",
    "        #negative_attention = self.attention_mask[negative_idx]\n",
    "        negative_example = self.dataset[negative_idx]\n",
    "\n",
    "        return anchor, positive_example, negative_example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_ds = TweetDataset(split_dataset['train'])\n",
    "test_ds = TweetDataset(split_dataset['test'])\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class TweetBERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-cased\")\n",
    "        self.pooler = torch.nn.Linear(768, 768)\n",
    "        self.tahn = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(**x)\n",
    "        x = self.pooler(x[0][:, 0])\n",
    "        return self.tahn(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = TweetBERT()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model = model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "loss = TripletMarginLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konsz\\AppData\\Local\\Temp\\ipykernel_21068\\1568605475.py:1: NeptuneDeprecationWarning: `init` is deprecated, use `init_run` instead. We'll end support of it in `neptune-client==1.0.0`.\n",
      "  run = neptune.init(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/konradszewczyk/TweetBuble/e/BUBL-39\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1125 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"konradszewczyk/TweetBuble\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI0MWIyOTA1ZS03ODc3LTQ5MzQtYjk0OS05ZjNjYzdiMDFjMDcifQ==\",\n",
    ")\n",
    "\n",
    "os.mkdir(os.path.join('models', run['sys/id'].fetch()))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss_log = []\n",
    "    for batch_idx, (anchor, positive_ex, negative_ex) in enumerate(tqdm(train_dl)):\n",
    "        #anchor = anchor.to(device=device)\n",
    "        anchor = {k: v.to(device) for k, v in anchor.items()}\n",
    "        archor_output = model(anchor)\n",
    "\n",
    "        #positive_ex = positive_ex.to(device=device)\n",
    "        positive_ex = {k: v[0].to(device) for k, v in positive_ex.items()}\n",
    "        positive_ex_output = model(positive_ex)\n",
    "\n",
    "        #negative_ex = negative_ex.to(device=device)\n",
    "        negative_ex = {k: v[0].to(device) for k, v in negative_ex.items()}\n",
    "        negative_ex_output = model(negative_ex)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss(archor_output, positive_ex_output, negative_ex_output)\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_log.append(train_loss.detach().cpu())\n",
    "\n",
    "    train_loss = np.mean(train_loss_log)\n",
    "    run['train_loss'].log(train_loss)\n",
    "    print(\"Epoch {:02d} train: {:.5f}\".format(epoch, train_loss))\n",
    "\n",
    "    file_name = 'epoch-{:02d}.pt'.format(epoch)\n",
    "    PATH = os.path.join('models', run['sys/id'].fetch(), file_name)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss_log = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (anchor, positive_ex, negative_ex) in enumerate(tqdm(test_dl)):\n",
    "            #anchor = anchor.to(device=device)\n",
    "            anchor = {k: v.to(device) for k, v in anchor.items()}\n",
    "            archor_output = model(anchor)\n",
    "\n",
    "            #positive_ex = positive_ex.to(device=device)\n",
    "            positive_ex = {k: v[0].to(device) for k, v in positive_ex.items()}\n",
    "            positive_ex_output = model(positive_ex)\n",
    "\n",
    "            #negative_ex = negative_ex.to(device=device)\n",
    "            negative_ex = {k: v[0].to(device) for k, v in negative_ex.items()}\n",
    "            negative_ex_output = model(negative_ex)\n",
    "\n",
    "            test_loss = loss(archor_output, positive_ex_output, negative_ex_output)\n",
    "\n",
    "            test_loss_log.append(test_loss.cpu())\n",
    "\n",
    "    test_loss = np.mean(test_loss_log)\n",
    "    run['test_loss'].log(test_loss)\n",
    "    print(\"Epoch {:02d} val: {:.5f}\".format(epoch, test_loss))\n",
    "\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d23b1cc31408ba59c72afb03ce07d8c08db8e1ae7bdb80d27747a1bfbd8e34d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}